{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"rumor_detection_acl2017/twitter15/tree\" \n",
    "path2 = \"rumor_detection_acl2017/twitter16/tree\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = [\"''\", \",\", \"[]\", \"->\", \"-\", \">\", \"[\", \"]\", \"'\", \"R\", \"O\", \"T\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tweetns15 = {}\n",
    "dict_tweetns16 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(path1):\n",
    "    s = str(file)\n",
    "    s = s.replace(\".txt\", \"\")\n",
    "    if s not in dict_tweetns15.keys():\n",
    "        dict_tweetns15[s] = []\n",
    "    ff = path1 + \"/\" + str(file)\n",
    "    t = []\n",
    "    xt = set()\n",
    "    with open(ff, 'r') as f1:\n",
    "        for line in f1:\n",
    "            line =  line.rstrip(\"\\n\")\n",
    "            t.append(line)\n",
    "    for e in t:\n",
    "        for char in e:\n",
    "            if char in punc:\n",
    "                if char == \">\":\n",
    "                    e = e.replace(char, \" \")\n",
    "                else:\n",
    "                    e = e.replace(char, \"\")\n",
    "        e = e.strip()  \n",
    "        l = e.split()\n",
    "        if len(l) == 4:\n",
    "            tup = (int(l[1]), float(l[3]))\n",
    "            xt.add(tup)\n",
    "        else:\n",
    "            tup = (int(l[3]), float(l[5]))\n",
    "            xt.add(tup)\n",
    "    xtl = list(xt)\n",
    "    xtl1 = sorted(xtl, key = lambda x: x[1])\n",
    "    dict_tweetns15[s] = xtl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_tweetns15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(path2):\n",
    "    s = str(file)\n",
    "    s = s.replace(\".txt\", \"\")\n",
    "    if s not in dict_tweetns16.keys():\n",
    "        dict_tweetns16[s] = []\n",
    "    ff = path2 + \"/\" + str(file)\n",
    "    t = []\n",
    "    xt = set()\n",
    "    with open(ff, 'r') as f2:\n",
    "        for line in f2:\n",
    "            line =  line.rstrip(\"\\n\")\n",
    "            t.append(line)\n",
    "    for e in t:\n",
    "        for char in e:\n",
    "            if char in punc:\n",
    "                if char == \">\":\n",
    "                    e = e.replace(char, \" \")\n",
    "                else:\n",
    "                    e = e.replace(char, \"\")\n",
    "        e = e.strip()  \n",
    "        l = e.split()\n",
    "        if len(l) == 4:\n",
    "            tup = (int(l[1]), float(l[3]))\n",
    "            xt.add(tup)\n",
    "        else:\n",
    "            tup = (int(l[3]), float(l[5]))\n",
    "            xt.add(tup)\n",
    "    xtl = list(xt)\n",
    "    xtl1 = sorted(xtl, key = lambda x: x[1])\n",
    "    dict_tweetns16[s] = xtl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_tweetns16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict15_to_write = open(\"dict_tweetns15.pickle\", \"wb\")\n",
    "pickle.dump(dict_tweetns15, dict15_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict16_to_write = open(\"dict_tweetns16.pickle\", \"wb\")\n",
    "pickle.dump(dict_tweetns16, dict16_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict15_to_read = open(\"dict_tweetns15.pickle\", \"rb\")\n",
    "loaded_dict15 = pickle.load(dict15_to_read)\n",
    "print(len(loaded_dict15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict16_to_read = open(\"dict_tweetns16.pickle\", \"rb\")\n",
    "loaded_dict16 = pickle.load(dict16_to_read)\n",
    "print(len(loaded_dict16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_secret = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token_secret = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_year = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11,\n",
    "             'Dec': 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dto = date(2021, 2, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path3 = \"Twitter15_dict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(path3):\n",
    "    s = str(file)\n",
    "    s = s.replace(\".txt\", \"\")\n",
    "    s = s.replace(\"dict\", \"\")\n",
    "    if s in loaded_dict15.keys():\n",
    "        del loaded_dict15[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loaded_dict15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for tweet in loaded_dict15.keys():\n",
    "    count = count + 1\n",
    "    print(count)\n",
    "    lid = loaded_dict15[tweet]\n",
    "    listt = []\n",
    "    for tups in lid:\n",
    "        c = 0\n",
    "        uid = tups[0]\n",
    "        try:\n",
    "            p = api.get_user(uid)\n",
    "        except tw.TweepError as e:\n",
    "            c = c + 1\n",
    "            print(\"Error! User not found. \" + str(tups[0]))\n",
    "        if c == 0:\n",
    "            time = tups[1]\n",
    "            tup1 = ([], time)\n",
    "            tup1[0].append(len(p._json['description']))\n",
    "            tup1[0].append(len(p._json['screen_name']))\n",
    "            tup1[0].append(p._json['followers_count'])\n",
    "            tup1[0].append(p._json['friends_count'])\n",
    "            tup1[0].append(p._json['statuses_count'])\n",
    "            pdate = list(p._json['created_at'].split())\n",
    "            d = pdate[2]\n",
    "            if d[0] == '0':\n",
    "                d = pdate[2].replace('0', \"\")\n",
    "            d = int(d)\n",
    "            m = month_year[pdate[1]]\n",
    "            y = int(pdate[-1])\n",
    "            age = int(((dto - date(y, m, d)).days)/365)\n",
    "            tup1[0].append(age)\n",
    "            x1 = p._json['verified']\n",
    "            if x1 == 'True' or x1 == 'true':\n",
    "                tup1[0].append(1)\n",
    "            else:\n",
    "                tup1[0].append(0)   \n",
    "            x2 = p._json['geo_enabled']\n",
    "            if x2 == 'True' or x2 == 'true':\n",
    "                tup1[0].append(1)\n",
    "            else:\n",
    "                tup1[0].append(0)\n",
    "            listt.append(tup1)\n",
    "    filename = \"dict\" + tweet + \".txt\"\n",
    "    with open(os.path.join(path3, filename), 'w+') as fl:\n",
    "        for items in listt:\n",
    "            fl.write(str(items) + '\\n') \n",
    "    fl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
